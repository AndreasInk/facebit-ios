{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('smart-ppe': conda)",
   "metadata": {
    "interpreter": {
     "hash": "ebfc23dd56157793abe8cac1db3fa05c2a64cc31687f593f29da3d897184b334"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:root:scikit-learn version 0.23.2 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import coremltools as ct\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    x = 2 * ( (x - np.min(x)) / (np.max(x) - np.min(x)) ) - 1\n",
    "    return x\n",
    "\n",
    "\n",
    "def demean(x):\n",
    "    x = x - np.mean(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clss = [0,1,2,4] # mask_off, normal_breathing, talking, cough\n",
    "X_train, Y_train, X_test, Y_test = [], [], [], []\n",
    "\n",
    "\n",
    "data_files = []\n",
    "for root, subdirs, files in os.walk('data/train'):\n",
    "    if len(files) == 0: continue\n",
    "    \n",
    "    for file in files:\n",
    "        data_files.append(f'{root.split(\"/\")[-1]}/{file}')\n",
    "\n",
    "for file in data_files:\n",
    "    train = np.load(f'data/train/{file}')\n",
    "    test = np.load(f'data/test/{file}')\n",
    "\n",
    "    # normalize sample\n",
    "    for s in train:\n",
    "        sample = np.vstack((\n",
    "                demean(s[0]),\n",
    "                demean(s[1])\n",
    "            ))\n",
    "        X_train.append(sample)\n",
    "        if 'mask_off' in file: Y_train.append(0)\n",
    "        elif 'normal_breathing' in file: Y_train.append(1)\n",
    "        elif 'talking' in file: Y_train.append(2)\n",
    "        elif 'cough' in file: Y_train.append(3)\n",
    "\n",
    "    for s in test:\n",
    "        X_test.append(\n",
    "            np.vstack((\n",
    "                demean(s[0]),\n",
    "                demean(s[1])\n",
    "            ))\n",
    "        )\n",
    "        if 'mask_off' in file: Y_test.append(0)\n",
    "        elif 'normal_breathing' in file: Y_test.append(1)\n",
    "        elif 'talking' in file: Y_test.append(2)\n",
    "        elif 'cough' in file: Y_test.append(3)\n",
    "    \n",
    "X_train, Y_train, X_test, Y_test = np.array(X_train, dtype='float64'), np.array(Y_train, dtype='float64'), np.array(X_test, dtype='float64'), np.array(Y_test, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(2,51), name='input'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    # tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, name='classification')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True ),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput (Flatten)              (None, 102)               0         \n_________________________________________________________________\ndense (Dense)                (None, 16)                1648      \n_________________________________________________________________\nclassification (Dense)       (None, 4)                 68        \n=================================================================\nTotal params: 1,716\nTrainable params: 1,716\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(771, 2, 51)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 840us/step - loss: 0.2092 - accuracy: 0.9505\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 851us/step - loss: 0.2089 - accuracy: 0.9505\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2086 - accuracy: 0.9505\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2083 - accuracy: 0.9505\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 877us/step - loss: 0.2080 - accuracy: 0.9505\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2077 - accuracy: 0.9505\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2074 - accuracy: 0.9505\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2072 - accuracy: 0.9505\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 643us/step - loss: 0.2069 - accuracy: 0.9505\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 748us/step - loss: 0.2066 - accuracy: 0.9510\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2063 - accuracy: 0.9510\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.9510\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 751us/step - loss: 0.2058 - accuracy: 0.9510\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 872us/step - loss: 0.2055 - accuracy: 0.9510\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 989us/step - loss: 0.2052 - accuracy: 0.9510\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 806us/step - loss: 0.2049 - accuracy: 0.9510\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2046 - accuracy: 0.9510\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2044 - accuracy: 0.9510\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 832us/step - loss: 0.2041 - accuracy: 0.9510\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 704us/step - loss: 0.2038 - accuracy: 0.9510\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 799us/step - loss: 0.2035 - accuracy: 0.9510\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 924us/step - loss: 0.2033 - accuracy: 0.9510\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 923us/step - loss: 0.2030 - accuracy: 0.9510\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 845us/step - loss: 0.2027 - accuracy: 0.9510\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2025 - accuracy: 0.9516\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2022 - accuracy: 0.9516\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 853us/step - loss: 0.2019 - accuracy: 0.9516\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 790us/step - loss: 0.2017 - accuracy: 0.9516\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 715us/step - loss: 0.2014 - accuracy: 0.9516\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2011 - accuracy: 0.9516\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2009 - accuracy: 0.9521\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2006 - accuracy: 0.9521\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2003 - accuracy: 0.9521\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 765us/step - loss: 0.2001 - accuracy: 0.9521\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 735us/step - loss: 0.1998 - accuracy: 0.9521\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 771us/step - loss: 0.1995 - accuracy: 0.9521\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1993 - accuracy: 0.9521\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1990 - accuracy: 0.9521\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1988 - accuracy: 0.9521\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 848us/step - loss: 0.1985 - accuracy: 0.9521\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1983 - accuracy: 0.9521\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 735us/step - loss: 0.1980 - accuracy: 0.9521\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1977 - accuracy: 0.9526\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1975 - accuracy: 0.9526\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1972 - accuracy: 0.9526\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 797us/step - loss: 0.1970 - accuracy: 0.9526\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 936us/step - loss: 0.1967 - accuracy: 0.9526\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 825us/step - loss: 0.1965 - accuracy: 0.9526\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 875us/step - loss: 0.1962 - accuracy: 0.9526\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 932us/step - loss: 0.1960 - accuracy: 0.9526\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1957 - accuracy: 0.9526\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.9532\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 710us/step - loss: 0.1952 - accuracy: 0.9532\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 758us/step - loss: 0.1950 - accuracy: 0.9532\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 981us/step - loss: 0.1947 - accuracy: 0.9532\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 810us/step - loss: 0.1945 - accuracy: 0.9532\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 894us/step - loss: 0.1943 - accuracy: 0.9532\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 827us/step - loss: 0.1940 - accuracy: 0.9532\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.9532\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 781us/step - loss: 0.1935 - accuracy: 0.9532\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 836us/step - loss: 0.1933 - accuracy: 0.9532\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 738us/step - loss: 0.1930 - accuracy: 0.9532\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 0.9537\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 703us/step - loss: 0.1926 - accuracy: 0.9537\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 841us/step - loss: 0.1923 - accuracy: 0.9543\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 868us/step - loss: 0.1921 - accuracy: 0.9543\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 712us/step - loss: 0.1918 - accuracy: 0.9543\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 953us/step - loss: 0.1916 - accuracy: 0.9543\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 873us/step - loss: 0.1914 - accuracy: 0.9543\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1911 - accuracy: 0.9543\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 839us/step - loss: 0.1909 - accuracy: 0.9543\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 885us/step - loss: 0.1907 - accuracy: 0.9543\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1904 - accuracy: 0.9543\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 929us/step - loss: 0.1902 - accuracy: 0.9543\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 887us/step - loss: 0.1900 - accuracy: 0.9543\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 845us/step - loss: 0.1897 - accuracy: 0.9543\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1895 - accuracy: 0.9543\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 785us/step - loss: 0.1893 - accuracy: 0.9543\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.9543\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.9543\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9543\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.9543\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 898us/step - loss: 0.1881 - accuracy: 0.9543\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 924us/step - loss: 0.1879 - accuracy: 0.9543\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 781us/step - loss: 0.1877 - accuracy: 0.9543\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 956us/step - loss: 0.1874 - accuracy: 0.9543\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 0.9543\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 876us/step - loss: 0.1870 - accuracy: 0.9543\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 665us/step - loss: 0.1868 - accuracy: 0.9543\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 801us/step - loss: 0.1866 - accuracy: 0.9543\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 818us/step - loss: 0.1863 - accuracy: 0.9543\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.9543\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 911us/step - loss: 0.1859 - accuracy: 0.9548\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.9554\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.9554\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.9554\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 805us/step - loss: 0.1850 - accuracy: 0.9554\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 813us/step - loss: 0.1848 - accuracy: 0.9554\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 734us/step - loss: 0.1846 - accuracy: 0.9554\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.9554\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.9554\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 805us/step - loss: 0.1839 - accuracy: 0.9554\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 626us/step - loss: 0.1837 - accuracy: 0.9554\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 983us/step - loss: 0.1835 - accuracy: 0.9554\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.9554\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 797us/step - loss: 0.1830 - accuracy: 0.9554\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 861us/step - loss: 0.1828 - accuracy: 0.9554\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 811us/step - loss: 0.1826 - accuracy: 0.9554\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.9554\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.9554\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.9554\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.9554\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 973us/step - loss: 0.1815 - accuracy: 0.9554\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 738us/step - loss: 0.1813 - accuracy: 0.9554\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 717us/step - loss: 0.1811 - accuracy: 0.9554\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 753us/step - loss: 0.1809 - accuracy: 0.9554\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.9559\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.9559\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.9559\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.9559\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.9559\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1796 - accuracy: 0.9559\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.9559\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 911us/step - loss: 0.1792 - accuracy: 0.9559\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1790 - accuracy: 0.9559\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 772us/step - loss: 0.1788 - accuracy: 0.9559\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 788us/step - loss: 0.1786 - accuracy: 0.9559\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1784 - accuracy: 0.9559\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 688us/step - loss: 0.1782 - accuracy: 0.9559\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.9559\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 876us/step - loss: 0.1778 - accuracy: 0.9559\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 819us/step - loss: 0.1776 - accuracy: 0.9559\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1774 - accuracy: 0.9565\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 823us/step - loss: 0.1772 - accuracy: 0.9565\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 906us/step - loss: 0.1770 - accuracy: 0.9565\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 782us/step - loss: 0.1768 - accuracy: 0.9565\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.9570\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1764 - accuracy: 0.9570\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 661us/step - loss: 0.1762 - accuracy: 0.9570\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.9570\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 902us/step - loss: 0.1758 - accuracy: 0.9570\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.9570\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 801us/step - loss: 0.1754 - accuracy: 0.9575\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.9575\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1750 - accuracy: 0.9575\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.9575\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.9575\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 585us/step - loss: 0.1744 - accuracy: 0.9575\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 912us/step - loss: 0.1742 - accuracy: 0.9575\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 981us/step - loss: 0.1740 - accuracy: 0.9575\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1738 - accuracy: 0.9575\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 871us/step - loss: 0.1736 - accuracy: 0.9575\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 931us/step - loss: 0.1734 - accuracy: 0.9581\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 711us/step - loss: 0.1732 - accuracy: 0.9581\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 751us/step - loss: 0.1730 - accuracy: 0.9581\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 814us/step - loss: 0.1728 - accuracy: 0.9581\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 653us/step - loss: 0.1726 - accuracy: 0.9581\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 781us/step - loss: 0.1724 - accuracy: 0.9581\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1722 - accuracy: 0.9581\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 744us/step - loss: 0.1720 - accuracy: 0.9581\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 890us/step - loss: 0.1718 - accuracy: 0.9581\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 889us/step - loss: 0.1716 - accuracy: 0.9581\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9581\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.1712 - accuracy: 0.9581\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1711 - accuracy: 0.9581\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1709 - accuracy: 0.9581\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1707 - accuracy: 0.9581\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 899us/step - loss: 0.1705 - accuracy: 0.9581\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 707us/step - loss: 0.1703 - accuracy: 0.9581\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1701 - accuracy: 0.9581\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 833us/step - loss: 0.1699 - accuracy: 0.9581\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1697 - accuracy: 0.9581\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1695 - accuracy: 0.9586\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1694 - accuracy: 0.9586\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 719us/step - loss: 0.1692 - accuracy: 0.9586\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1690 - accuracy: 0.9586\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1688 - accuracy: 0.9586\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1686 - accuracy: 0.9586\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1684 - accuracy: 0.9586\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 849us/step - loss: 0.1682 - accuracy: 0.9586\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1681 - accuracy: 0.9586\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1679 - accuracy: 0.9586\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1677 - accuracy: 0.9586\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1675 - accuracy: 0.9586\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1673 - accuracy: 0.9586\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 768us/step - loss: 0.1671 - accuracy: 0.9586\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1670 - accuracy: 0.9586\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1668 - accuracy: 0.9586\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 0.9592\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 778us/step - loss: 0.1664 - accuracy: 0.9592\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1662 - accuracy: 0.9592\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1661 - accuracy: 0.9592\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 756us/step - loss: 0.1659 - accuracy: 0.9597\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 824us/step - loss: 0.1657 - accuracy: 0.9603\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1655 - accuracy: 0.9603\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1653 - accuracy: 0.9603\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1652 - accuracy: 0.9603\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 790us/step - loss: 0.1650 - accuracy: 0.9608\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc2b8e22a00>"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "model.fit(np.nan_to_num(X_train), Y_train, epochs=1000, batch_size=len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "25/25 - 0s - loss: 0.3514 - accuracy: 0.9040\n",
      "\n",
      "Test accuracy: 0.9040207266807556\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(np.nan_to_num(X_test),  Y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Running TensorFlow Graph Passes: 100%|██████████| 5/5 [00:00<00:00, 33.90 passes/s]\n",
      "Converting Frontend ==> MIL Ops: 100%|██████████| 13/13 [00:00<00:00, 1285.23 ops/s]\n",
      "Running MIL optimization passes: 100%|██████████| 18/18 [00:00<00:00, 1574.41 passes/s]\n",
      "Translating MIL ==> MLModel Ops: 100%|██████████| 9/9 [00:00<00:00, 7601.44 ops/s]\n"
     ]
    }
   ],
   "source": [
    "model.save('simple_nn')\n",
    "mlmodel = ct.convert('simple_nn') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlmodel.author = \"Blaine Rothrock\"\n",
    "mlmodel.short_description = \"Classification of 3 second temp and pressure data @ 17hz. Classes: Mask Off, Normal Breathing, Talking, Cough. Cough has very little representation\"\n",
    "mlmodel.version = \"0.0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlmodel.save('RespiratoryClassifier.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}