{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('smart-ppe': conda)",
   "metadata": {
    "interpreter": {
     "hash": "ebfc23dd56157793abe8cac1db3fa05c2a64cc31687f593f29da3d897184b334"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:root:scikit-learn version 0.23.2 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import coremltools as ct\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    x = 2 * ( (x - np.min(x)) / (np.max(x) - np.min(x)) ) - 1\n",
    "    return x\n",
    "\n",
    "\n",
    "def demean(x):\n",
    "    x = x - np.mean(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['talking/s_2021-02-11T01:37:39.912Z.npy', 'talking/s_2021-02-11T01:55:17.151Z.npy', 'talking/s_2021-02-11T02:16:45.294Z.npy', 'talking/s_2021-02-10 18:34:39.763.npy', 'talking/s_2021-02-11T02:17:25.710Z.npy', 'talking/s_2021-02-10 16:36:38.417.npy', 'talking/s_2021-02-11T02:18:05.753Z.npy', 'talking/s_2021-02-11T01:53:39.682Z.npy', 'talking/s_2021-02-11T02:16:02.647Z.npy', 'talking/s_2021-02-11T01:38:19.935Z.npy', 'talking/s_2021-02-11T02:15:23.053Z.npy', 'talking/s_2021-02-11T01:54:29.064Z.npy', 'cough/s_2021-02-10 22:18:44.719.npy', 'cough/s_2021-02-10 20:53:33.741.npy', 'cough/s_2021-02-10 22:18:17.501.npy', 'cough/s_2021-02-10 20:57:59.617.npy', 'normal_breathing/s_2021-02-11T02:10:12.422Z.npy', 'normal_breathing/s_2021-02-11T02:10:52.762Z.npy', 'normal_breathing/s_2021-02-10 15:11:17.966.npy', 'normal_breathing/s_2021-02-11T02:08:10.624Z.npy', 'normal_breathing/s_2021-02-10 18:12:14.117.npy', 'normal_breathing/s_2021-02-11T02:08:51.770Z.npy', 'normal_breathing/s_2021-02-11T01:31:43.063Z.npy', 'normal_breathing/s_2021-02-11T01:33:06.699Z.npy', 'normal_breathing/s_2021-02-11T01:31:00.243Z.npy', 'normal_breathing/s_2021-02-11T02:09:32.034Z.npy', 'normal_breathing/s_2021-02-11T01:29:59.773Z.npy', 'mask_off/s_2021-02-10 16:24:58.357.npy', 'mask_off/s_2021-02-10 18:27:53.484.npy']\n"
     ]
    }
   ],
   "source": [
    "clss = [0,1,2,4] # mask_off, normal_breathing, talking, cough\n",
    "X_train, Y_train, X_test, Y_test = [], [], [], []\n",
    "\n",
    "\n",
    "data_files = []\n",
    "for root, subdirs, files in os.walk('data/train'):\n",
    "    if len(files) == 0: continue\n",
    "    \n",
    "    for file in files:\n",
    "        data_files.append(f'{root.split(\"/\")[-1]}/{file}')\n",
    "\n",
    "print(data_files)\n",
    "\n",
    "\n",
    "for file in data_files:\n",
    "    train = np.load(f'data/train/{file}')\n",
    "    test = np.load(f'data/test/{file}')\n",
    "\n",
    "    # normalize sample\n",
    "    for s in train:\n",
    "        sample = np.vstack((\n",
    "                demean(s[0]),\n",
    "                demean(s[1])\n",
    "            ))\n",
    "        X_train.append(sample)\n",
    "        if 'mask_off' in file: Y_train.append(0)\n",
    "        elif 'normal_breathing' in file: Y_train.append(1)\n",
    "        elif 'talking' in file: Y_train.append(2)\n",
    "        elif 'cough' in file: Y_train.append(3)\n",
    "\n",
    "    for s in test:\n",
    "        X_test.append(\n",
    "            np.vstack((\n",
    "                demean(s[0]),\n",
    "                demean(s[1])\n",
    "            ))\n",
    "        )\n",
    "        if 'mask_off' in file: Y_test.append(0)\n",
    "        elif 'normal_breathing' in file: Y_test.append(1)\n",
    "        elif 'talking' in file: Y_test.append(2)\n",
    "        elif 'cough' in file: Y_test.append(3)\n",
    "    \n",
    "X_train, Y_train, X_test, Y_test = np.array(X_train, dtype='float64'), np.array(Y_train, dtype='float64'), np.array(X_test, dtype='float64'), np.array(Y_test, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(2,51), name='input'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, name='classification')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True ),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput (Flatten)              (None, 102)               0         \n_________________________________________________________________\ndense_10 (Dense)             (None, 32)                3296      \n_________________________________________________________________\ndense_11 (Dense)             (None, 16)                528       \n_________________________________________________________________\nclassification (Dense)       (None, 4)                 68        \n=================================================================\nTotal params: 3,892\nTrainable params: 3,892\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 551/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0563 - accuracy: 0.9869\n",
      "Epoch 552/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9869\n",
      "Epoch 553/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0558 - accuracy: 0.9869\n",
      "Epoch 554/750\n",
      "1/1 [==============================] - 0s 962us/step - loss: 0.0556 - accuracy: 0.9869\n",
      "Epoch 555/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.9869\n",
      "Epoch 556/750\n",
      "1/1 [==============================] - 0s 749us/step - loss: 0.0551 - accuracy: 0.9869\n",
      "Epoch 557/750\n",
      "1/1 [==============================] - 0s 825us/step - loss: 0.0548 - accuracy: 0.9869\n",
      "Epoch 558/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0546 - accuracy: 0.9869\n",
      "Epoch 559/750\n",
      "1/1 [==============================] - 0s 770us/step - loss: 0.0543 - accuracy: 0.9875\n",
      "Epoch 560/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0541 - accuracy: 0.9875\n",
      "Epoch 561/750\n",
      "1/1 [==============================] - 0s 901us/step - loss: 0.0539 - accuracy: 0.9875\n",
      "Epoch 562/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.9875\n",
      "Epoch 563/750\n",
      "1/1 [==============================] - 0s 617us/step - loss: 0.0534 - accuracy: 0.9875\n",
      "Epoch 564/750\n",
      "1/1 [==============================] - 0s 960us/step - loss: 0.0531 - accuracy: 0.9875\n",
      "Epoch 565/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9875\n",
      "Epoch 566/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0527 - accuracy: 0.9875\n",
      "Epoch 567/750\n",
      "1/1 [==============================] - 0s 941us/step - loss: 0.0524 - accuracy: 0.9875\n",
      "Epoch 568/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 0.9875\n",
      "Epoch 569/750\n",
      "1/1 [==============================] - 0s 836us/step - loss: 0.0520 - accuracy: 0.9880\n",
      "Epoch 570/750\n",
      "1/1 [==============================] - 0s 696us/step - loss: 0.0518 - accuracy: 0.9880\n",
      "Epoch 571/750\n",
      "1/1 [==============================] - 0s 783us/step - loss: 0.0515 - accuracy: 0.9880\n",
      "Epoch 572/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0513 - accuracy: 0.9880\n",
      "Epoch 573/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0511 - accuracy: 0.9880\n",
      "Epoch 574/750\n",
      "1/1 [==============================] - 0s 767us/step - loss: 0.0509 - accuracy: 0.9885\n",
      "Epoch 575/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0506 - accuracy: 0.9885\n",
      "Epoch 576/750\n",
      "1/1 [==============================] - 0s 717us/step - loss: 0.0504 - accuracy: 0.9885\n",
      "Epoch 577/750\n",
      "1/1 [==============================] - 0s 939us/step - loss: 0.0502 - accuracy: 0.9891\n",
      "Epoch 578/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0500 - accuracy: 0.9891\n",
      "Epoch 579/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0497 - accuracy: 0.9896\n",
      "Epoch 580/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0495 - accuracy: 0.9896\n",
      "Epoch 581/750\n",
      "1/1 [==============================] - 0s 720us/step - loss: 0.0493 - accuracy: 0.9896\n",
      "Epoch 582/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0491 - accuracy: 0.9896\n",
      "Epoch 583/750\n",
      "1/1 [==============================] - 0s 916us/step - loss: 0.0489 - accuracy: 0.9896\n",
      "Epoch 584/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9896\n",
      "Epoch 585/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 0.9896\n",
      "Epoch 586/750\n",
      "1/1 [==============================] - 0s 978us/step - loss: 0.0482 - accuracy: 0.9896\n",
      "Epoch 587/750\n",
      "1/1 [==============================] - 0s 970us/step - loss: 0.0480 - accuracy: 0.9896\n",
      "Epoch 588/750\n",
      "1/1 [==============================] - 0s 765us/step - loss: 0.0478 - accuracy: 0.9902\n",
      "Epoch 589/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0476 - accuracy: 0.9902\n",
      "Epoch 590/750\n",
      "1/1 [==============================] - 0s 876us/step - loss: 0.0473 - accuracy: 0.9902\n",
      "Epoch 591/750\n",
      "1/1 [==============================] - 0s 804us/step - loss: 0.0471 - accuracy: 0.9902\n",
      "Epoch 592/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0469 - accuracy: 0.9902\n",
      "Epoch 593/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0467 - accuracy: 0.9902\n",
      "Epoch 594/750\n",
      "1/1 [==============================] - 0s 852us/step - loss: 0.0465 - accuracy: 0.9902\n",
      "Epoch 595/750\n",
      "1/1 [==============================] - 0s 978us/step - loss: 0.0463 - accuracy: 0.9902\n",
      "Epoch 596/750\n",
      "1/1 [==============================] - 0s 727us/step - loss: 0.0461 - accuracy: 0.9902\n",
      "Epoch 597/750\n",
      "1/1 [==============================] - 0s 986us/step - loss: 0.0459 - accuracy: 0.9902\n",
      "Epoch 598/750\n",
      "1/1 [==============================] - 0s 940us/step - loss: 0.0456 - accuracy: 0.9907\n",
      "Epoch 599/750\n",
      "1/1 [==============================] - 0s 698us/step - loss: 0.0454 - accuracy: 0.9913\n",
      "Epoch 600/750\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 0.9913\n",
      "Epoch 601/750\n",
      "1/1 [==============================] - 0s 800us/step - loss: 0.0450 - accuracy: 0.9913\n",
      "Epoch 602/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0448 - accuracy: 0.9913\n",
      "Epoch 603/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.9913\n",
      "Epoch 604/750\n",
      "1/1 [==============================] - 0s 719us/step - loss: 0.0444 - accuracy: 0.9913\n",
      "Epoch 605/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0442 - accuracy: 0.9913\n",
      "Epoch 606/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0440 - accuracy: 0.9913\n",
      "Epoch 607/750\n",
      "1/1 [==============================] - 0s 870us/step - loss: 0.0438 - accuracy: 0.9913\n",
      "Epoch 608/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0437 - accuracy: 0.9913\n",
      "Epoch 609/750\n",
      "1/1 [==============================] - 0s 824us/step - loss: 0.0435 - accuracy: 0.9913\n",
      "Epoch 610/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0433 - accuracy: 0.9913\n",
      "Epoch 611/750\n",
      "1/1 [==============================] - 0s 777us/step - loss: 0.0431 - accuracy: 0.9913\n",
      "Epoch 612/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0429 - accuracy: 0.9913\n",
      "Epoch 613/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0427 - accuracy: 0.9913\n",
      "Epoch 614/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0425 - accuracy: 0.9913\n",
      "Epoch 615/750\n",
      "1/1 [==============================] - 0s 788us/step - loss: 0.0423 - accuracy: 0.9913\n",
      "Epoch 616/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0421 - accuracy: 0.9913\n",
      "Epoch 617/750\n",
      "1/1 [==============================] - 0s 944us/step - loss: 0.0420 - accuracy: 0.9913\n",
      "Epoch 618/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 0.9913\n",
      "Epoch 619/750\n",
      "1/1 [==============================] - 0s 840us/step - loss: 0.0416 - accuracy: 0.9913\n",
      "Epoch 620/750\n",
      "1/1 [==============================] - 0s 846us/step - loss: 0.0414 - accuracy: 0.9918\n",
      "Epoch 621/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 0.9924\n",
      "Epoch 622/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9924\n",
      "Epoch 623/750\n",
      "1/1 [==============================] - 0s 970us/step - loss: 0.0409 - accuracy: 0.9918\n",
      "Epoch 624/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0407 - accuracy: 0.9924\n",
      "Epoch 625/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0405 - accuracy: 0.9929\n",
      "Epoch 626/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0403 - accuracy: 0.9929\n",
      "Epoch 627/750\n",
      "1/1 [==============================] - 0s 890us/step - loss: 0.0402 - accuracy: 0.9929\n",
      "Epoch 628/750\n",
      "1/1 [==============================] - 0s 728us/step - loss: 0.0400 - accuracy: 0.9929\n",
      "Epoch 629/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0398 - accuracy: 0.9929\n",
      "Epoch 630/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0396 - accuracy: 0.9935\n",
      "Epoch 631/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9935\n",
      "Epoch 632/750\n",
      "1/1 [==============================] - 0s 686us/step - loss: 0.0393 - accuracy: 0.9940\n",
      "Epoch 633/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0391 - accuracy: 0.9940\n",
      "Epoch 634/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0390 - accuracy: 0.9945\n",
      "Epoch 635/750\n",
      "1/1 [==============================] - 0s 691us/step - loss: 0.0388 - accuracy: 0.9940\n",
      "Epoch 636/750\n",
      "1/1 [==============================] - 0s 922us/step - loss: 0.0386 - accuracy: 0.9940\n",
      "Epoch 637/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9951\n",
      "Epoch 638/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0383 - accuracy: 0.9951\n",
      "Epoch 639/750\n",
      "1/1 [==============================] - 0s 708us/step - loss: 0.0381 - accuracy: 0.9951\n",
      "Epoch 640/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 0.9951\n",
      "Epoch 641/750\n",
      "1/1 [==============================] - 0s 745us/step - loss: 0.0378 - accuracy: 0.9951\n",
      "Epoch 642/750\n",
      "1/1 [==============================] - 0s 976us/step - loss: 0.0376 - accuracy: 0.9951\n",
      "Epoch 643/750\n",
      "1/1 [==============================] - 0s 723us/step - loss: 0.0375 - accuracy: 0.9951\n",
      "Epoch 644/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0373 - accuracy: 0.9951\n",
      "Epoch 645/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0372 - accuracy: 0.9951\n",
      "Epoch 646/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9951\n",
      "Epoch 647/750\n",
      "1/1 [==============================] - 0s 946us/step - loss: 0.0368 - accuracy: 0.9951\n",
      "Epoch 648/750\n",
      "1/1 [==============================] - 0s 824us/step - loss: 0.0367 - accuracy: 0.9951\n",
      "Epoch 649/750\n",
      "1/1 [==============================] - 0s 714us/step - loss: 0.0365 - accuracy: 0.9951\n",
      "Epoch 650/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9951\n",
      "Epoch 651/750\n",
      "1/1 [==============================] - 0s 708us/step - loss: 0.0362 - accuracy: 0.9951\n",
      "Epoch 652/750\n",
      "1/1 [==============================] - 0s 899us/step - loss: 0.0361 - accuracy: 0.9951\n",
      "Epoch 653/750\n",
      "1/1 [==============================] - 0s 819us/step - loss: 0.0359 - accuracy: 0.9951\n",
      "Epoch 654/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9951\n",
      "Epoch 655/750\n",
      "1/1 [==============================] - 0s 761us/step - loss: 0.0356 - accuracy: 0.9951\n",
      "Epoch 656/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9956\n",
      "Epoch 657/750\n",
      "1/1 [==============================] - 0s 876us/step - loss: 0.0353 - accuracy: 0.9956\n",
      "Epoch 658/750\n",
      "1/1 [==============================] - 0s 732us/step - loss: 0.0352 - accuracy: 0.9956\n",
      "Epoch 659/750\n",
      "1/1 [==============================] - 0s 749us/step - loss: 0.0350 - accuracy: 0.9956\n",
      "Epoch 660/750\n",
      "1/1 [==============================] - 0s 932us/step - loss: 0.0349 - accuracy: 0.9956\n",
      "Epoch 661/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9956\n",
      "Epoch 662/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9956\n",
      "Epoch 663/750\n",
      "1/1 [==============================] - 0s 966us/step - loss: 0.0344 - accuracy: 0.9956\n",
      "Epoch 664/750\n",
      "1/1 [==============================] - 0s 776us/step - loss: 0.0343 - accuracy: 0.9956\n",
      "Epoch 665/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 0.9962\n",
      "Epoch 666/750\n",
      "1/1 [==============================] - 0s 721us/step - loss: 0.0340 - accuracy: 0.9962\n",
      "Epoch 667/750\n",
      "1/1 [==============================] - 0s 926us/step - loss: 0.0339 - accuracy: 0.9962\n",
      "Epoch 668/750\n",
      "1/1 [==============================] - 0s 968us/step - loss: 0.0337 - accuracy: 0.9962\n",
      "Epoch 669/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0336 - accuracy: 0.9962\n",
      "Epoch 670/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0334 - accuracy: 0.9962\n",
      "Epoch 671/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0333 - accuracy: 0.9962\n",
      "Epoch 672/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 0.9962\n",
      "Epoch 673/750\n",
      "1/1 [==============================] - 0s 820us/step - loss: 0.0330 - accuracy: 0.9962\n",
      "Epoch 674/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9962\n",
      "Epoch 675/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9962\n",
      "Epoch 676/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0326 - accuracy: 0.9962\n",
      "Epoch 677/750\n",
      "1/1 [==============================] - 0s 814us/step - loss: 0.0325 - accuracy: 0.9962\n",
      "Epoch 678/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9962\n",
      "Epoch 679/750\n",
      "1/1 [==============================] - 0s 903us/step - loss: 0.0322 - accuracy: 0.9962\n",
      "Epoch 680/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 0.9962\n",
      "Epoch 681/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9962\n",
      "Epoch 682/750\n",
      "1/1 [==============================] - 0s 783us/step - loss: 0.0318 - accuracy: 0.9962\n",
      "Epoch 683/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0317 - accuracy: 0.9962\n",
      "Epoch 684/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0316 - accuracy: 0.9962\n",
      "Epoch 685/750\n",
      "1/1 [==============================] - 0s 857us/step - loss: 0.0315 - accuracy: 0.9962\n",
      "Epoch 686/750\n",
      "1/1 [==============================] - 0s 730us/step - loss: 0.0313 - accuracy: 0.9962\n",
      "Epoch 687/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 0.9962\n",
      "Epoch 688/750\n",
      "1/1 [==============================] - 0s 935us/step - loss: 0.0311 - accuracy: 0.9962\n",
      "Epoch 689/750\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.0310 - accuracy: 0.9962\n",
      "Epoch 690/750\n",
      "1/1 [==============================] - 0s 850us/step - loss: 0.0308 - accuracy: 0.9962\n",
      "Epoch 691/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0307 - accuracy: 0.9962\n",
      "Epoch 692/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0306 - accuracy: 0.9962\n",
      "Epoch 693/750\n",
      "1/1 [==============================] - 0s 787us/step - loss: 0.0305 - accuracy: 0.9962\n",
      "Epoch 694/750\n",
      "1/1 [==============================] - 0s 771us/step - loss: 0.0303 - accuracy: 0.9962\n",
      "Epoch 695/750\n",
      "1/1 [==============================] - 0s 764us/step - loss: 0.0302 - accuracy: 0.9962\n",
      "Epoch 696/750\n",
      "1/1 [==============================] - 0s 883us/step - loss: 0.0301 - accuracy: 0.9962\n",
      "Epoch 697/750\n",
      "1/1 [==============================] - 0s 959us/step - loss: 0.0300 - accuracy: 0.9962\n",
      "Epoch 698/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.9962\n",
      "Epoch 699/750\n",
      "1/1 [==============================] - 0s 704us/step - loss: 0.0298 - accuracy: 0.9962\n",
      "Epoch 700/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0296 - accuracy: 0.9962\n",
      "Epoch 701/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9962\n",
      "Epoch 702/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0294 - accuracy: 0.9962\n",
      "Epoch 703/750\n",
      "1/1 [==============================] - 0s 701us/step - loss: 0.0293 - accuracy: 0.9962\n",
      "Epoch 704/750\n",
      "1/1 [==============================] - 0s 873us/step - loss: 0.0292 - accuracy: 0.9962\n",
      "Epoch 705/750\n",
      "1/1 [==============================] - 0s 707us/step - loss: 0.0291 - accuracy: 0.9962\n",
      "Epoch 706/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0289 - accuracy: 0.9962\n",
      "Epoch 707/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 0.9962\n",
      "Epoch 708/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.9962\n",
      "Epoch 709/750\n",
      "1/1 [==============================] - 0s 828us/step - loss: 0.0286 - accuracy: 0.9962\n",
      "Epoch 710/750\n",
      "1/1 [==============================] - 0s 786us/step - loss: 0.0285 - accuracy: 0.9962\n",
      "Epoch 711/750\n",
      "1/1 [==============================] - 0s 850us/step - loss: 0.0284 - accuracy: 0.9962\n",
      "Epoch 712/750\n",
      "1/1 [==============================] - 0s 974us/step - loss: 0.0283 - accuracy: 0.9962\n",
      "Epoch 713/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9962\n",
      "Epoch 714/750\n",
      "1/1 [==============================] - 0s 653us/step - loss: 0.0281 - accuracy: 0.9962\n",
      "Epoch 715/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9962\n",
      "Epoch 716/750\n",
      "1/1 [==============================] - 0s 746us/step - loss: 0.0278 - accuracy: 0.9962\n",
      "Epoch 717/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0277 - accuracy: 0.9962\n",
      "Epoch 718/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0276 - accuracy: 0.9962\n",
      "Epoch 719/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 0.9962\n",
      "Epoch 720/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0274 - accuracy: 0.9962\n",
      "Epoch 721/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 0.9962\n",
      "Epoch 722/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.9962\n",
      "Epoch 723/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.9962\n",
      "Epoch 724/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.9962\n",
      "Epoch 725/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.9962\n",
      "Epoch 726/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0268 - accuracy: 0.9962\n",
      "Epoch 727/750\n",
      "1/1 [==============================] - 0s 834us/step - loss: 0.0267 - accuracy: 0.9962\n",
      "Epoch 728/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9962\n",
      "Epoch 729/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0265 - accuracy: 0.9962\n",
      "Epoch 730/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 0.9962\n",
      "Epoch 731/750\n",
      "1/1 [==============================] - 0s 754us/step - loss: 0.0263 - accuracy: 0.9962\n",
      "Epoch 732/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 0.9962\n",
      "Epoch 733/750\n",
      "1/1 [==============================] - 0s 859us/step - loss: 0.0261 - accuracy: 0.9962\n",
      "Epoch 734/750\n",
      "1/1 [==============================] - 0s 938us/step - loss: 0.0260 - accuracy: 0.9962\n",
      "Epoch 735/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 0.9962\n",
      "Epoch 736/750\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.9962\n",
      "Epoch 737/750\n",
      "1/1 [==============================] - 0s 607us/step - loss: 0.0257 - accuracy: 0.9962\n",
      "Epoch 738/750\n",
      "1/1 [==============================] - 0s 841us/step - loss: 0.0256 - accuracy: 0.9962\n",
      "Epoch 739/750\n",
      "1/1 [==============================] - 0s 859us/step - loss: 0.0255 - accuracy: 0.9962\n",
      "Epoch 740/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9962\n",
      "Epoch 741/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0253 - accuracy: 0.9962\n",
      "Epoch 742/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9962\n",
      "Epoch 743/750\n",
      "1/1 [==============================] - 0s 848us/step - loss: 0.0251 - accuracy: 0.9962\n",
      "Epoch 744/750\n",
      "1/1 [==============================] - 0s 925us/step - loss: 0.0250 - accuracy: 0.9962\n",
      "Epoch 745/750\n",
      "1/1 [==============================] - 0s 844us/step - loss: 0.0249 - accuracy: 0.9962\n",
      "Epoch 746/750\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.9962\n",
      "Epoch 747/750\n",
      "1/1 [==============================] - 0s 960us/step - loss: 0.0248 - accuracy: 0.9962\n",
      "Epoch 748/750\n",
      "1/1 [==============================] - 0s 758us/step - loss: 0.0247 - accuracy: 0.9962\n",
      "Epoch 749/750\n",
      "1/1 [==============================] - 0s 805us/step - loss: 0.0246 - accuracy: 0.9962\n",
      "Epoch 750/750\n",
      "1/1 [==============================] - 0s 965us/step - loss: 0.0245 - accuracy: 0.9962\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc30910a130>"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "model.fit(np.nan_to_num(X_train), Y_train, epochs=750, batch_size=len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "25/25 - 0s - loss: 0.3935 - accuracy: 0.9416\n",
      "\n",
      "Test accuracy: 0.9415584206581116\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(np.nan_to_num(X_test),  Y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Running TensorFlow Graph Passes: 100%|██████████| 5/5 [00:00<00:00, 35.55 passes/s]\n",
      "Converting Frontend ==> MIL Ops: 100%|██████████| 18/18 [00:00<00:00, 1434.14 ops/s]\n",
      "Running MIL optimization passes: 100%|██████████| 18/18 [00:00<00:00, 1210.40 passes/s]\n",
      "Translating MIL ==> MLModel Ops: 100%|██████████| 13/13 [00:00<00:00, 12081.97 ops/s]\n"
     ]
    }
   ],
   "source": [
    "model.save('simple_nn')\n",
    "mlmodel = ct.convert('simple_nn') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlmodel.author = \"Blaine Rothrock\"\n",
    "mlmodel.short_description = \"Classification of 3 second temp and pressure data @ 17hz. Classes: Mask Off, Normal Breathing, Talking, Cough. Cough has very little representation\"\n",
    "mlmodel.version = \"0.0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlmodel.save('RespiratoryClassifier.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}