{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('smart-ppe': conda)",
   "metadata": {
    "interpreter": {
     "hash": "ebfc23dd56157793abe8cac1db3fa05c2a64cc31687f593f29da3d897184b334"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, math, os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateFeaturesStats(data = np.array([]),col_name=\"\"):\n",
    "    \n",
    "    \"\"\"Calculates features Mean, Variance, ZCR, and MCR\n",
    "    Parameters\n",
    "    ----------\n",
    "        data:                   numpy array\n",
    "    Return\n",
    "    ------\n",
    "        dict:\n",
    "        - dict.mean:            double\n",
    "        - dict.variance:        double\n",
    "        - dict.zcr:             int\n",
    "        - dict.mcr:             int\n",
    "    \"\"\"\n",
    "    if data.size == 0:\n",
    "        return \n",
    "    \n",
    "    f = []\n",
    "    rv = {}\n",
    "    rv[col_name+'_min'] = np.amin(data)\n",
    "    rv[col_name+'_max'] = np.amax(data)\n",
    "    rv[col_name+'_mean'] = np.mean(data)\n",
    "    rv[col_name+'_median'] = np.median(data)\n",
    "    rv[col_name+'_mode'] = stats.mode(data)[0][0]\n",
    "    rv[col_name+'_std'] = np.std(data)\n",
    "    rv[col_name+'_variance'] = np.var(data)\n",
    "    rv[col_name+'_skew'] = stats.skew(data,axis = 0)\n",
    "    rv[col_name+'_kur'] = stats.kurtosis(data,axis = 0)\n",
    "    rv[col_name+'_eightperc'] = np.percentile(data, 80,axis = 0)\n",
    "    rv[col_name+'_sixperc'] = np.percentile(data, 60,axis = 0)\n",
    "    rv[col_name+'_fourperc'] = np.percentile(data, 40,axis = 0)\n",
    "    rv[col_name+'_twoperc'] = np.percentile(data, 20,axis = 0)\n",
    "    rv[col_name+'_rms'] = np.sqrt(np.mean(data**2))\n",
    "    rv[col_name+'_iqr'] = stats.iqr(data,axis = 0)\n",
    "    rv[col_name+'_countgeq'] = len(np.where( data > rv[col_name+'_mean'])[0])/float(len(data))\n",
    "    rv[col_name+'_countleq'] = len(np.where( data < rv[col_name+'_mean'])[0])/float(len(data))\n",
    "    rv[col_name+'_range'] = rv[col_name+'_max'] - rv[col_name+'_min']\n",
    "    rv[col_name+'_zcr'] = (np.diff(np.sign(data)) != 0).sum()\n",
    "    \n",
    "    normalized = data - rv[col_name+'_mean']\n",
    "    rv[col_name+'_mcr'] = (np.diff(np.sign(normalized)) != 0).sum()\n",
    "\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    x = 2 * ( (x - np.min(x)) / (np.max(x) - np.min(x)) ) - 1\n",
    "    return x\n",
    "\n",
    "\n",
    "def demean(x):\n",
    "    x = x - np.mean(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data/train ['talking', 'cough', 'normal_breathing', 'mask_off'] []\ndata/train/talking [] ['s_2021-02-10 18:34:39.763.npy', 's_2021-02-10 16:36:38.417.npy']\ndata/train/cough [] ['s_2021-02-10 22:18:44.719.npy', 's_2021-02-10 20:53:33.741.npy', 's_2021-02-10 22:18:17.501.npy', 's_2021-02-10 20:57:59.617.npy']\ndata/train/normal_breathing [] ['s_2021-02-10 15:11:17.966.npy', 's_2021-02-10 18:12:14.117.npy']\ndata/train/mask_off [] ['s_2021-02-10 16:24:58.357.npy', 's_2021-02-10 18:27:53.484.npy']\n"
     ]
    }
   ],
   "source": [
    "for root, subdirs, files in os.walk('data/train'):\n",
    "    print(root, subdirs, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['talking/s_2021-02-10 18:34:39.763.npy', 'talking/s_2021-02-10 16:36:38.417.npy', 'cough/s_2021-02-10 22:18:44.719.npy', 'cough/s_2021-02-10 20:53:33.741.npy', 'cough/s_2021-02-10 22:18:17.501.npy', 'cough/s_2021-02-10 20:57:59.617.npy', 'normal_breathing/s_2021-02-10 15:11:17.966.npy', 'normal_breathing/s_2021-02-10 18:12:14.117.npy', 'mask_off/s_2021-02-10 16:24:58.357.npy', 'mask_off/s_2021-02-10 18:27:53.484.npy']\n"
     ]
    }
   ],
   "source": [
    "# data prep\n",
    "clss = [0,1,2] # mask_off, normal_breathing, talking\n",
    "X_train, Y_train, X_test, Y_test = [], [], [], []\n",
    "\n",
    "\n",
    "data_files = []\n",
    "for root, subdirs, files in os.walk('data/train'):\n",
    "    if len(files) == 0: continue\n",
    "    \n",
    "    for file in files:\n",
    "        data_files.append(f'{root.split(\"/\")[-1]}/{file}')\n",
    "\n",
    "print(data_files)\n",
    "\n",
    "\n",
    "for file in data_files:\n",
    "    train = np.load(f'data/train/{file}')\n",
    "    test = np.load(f'data/test/{file}')\n",
    "\n",
    "    # print(train[0][0] + train[0][1])\n",
    "\n",
    "    # normalize sample\n",
    "    for s in train:\n",
    "        X_train.append(demean(s[1]))\n",
    "        if 'mask_off' in file: Y_train.append(0)\n",
    "        elif 'normal_breathing' in file: Y_train.append(1)\n",
    "        elif 'talking' in file: Y_train.append(2)\n",
    "        elif 'cough' in file: Y_train.append(3)\n",
    "\n",
    "    for s in test:\n",
    "        X_test.append(demean(s[1]))\n",
    "        if 'mask_off' in file: Y_test.append(0)\n",
    "        elif 'normal_breathing' in file: Y_test.append(1)\n",
    "        elif 'talking' in file: Y_test.append(2)\n",
    "        elif 'cough' in file: Y_test.append(3)\n",
    "    \n",
    "X_train, Y_train, X_test, Y_test = np.array(X_train, dtype='float64'), np.array(Y_train, dtype='float64'), np.array(X_test, dtype='float64'), np.array(Y_test, dtype='float64') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1358, 60) (1358,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1358, 60)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(np.nan_to_num(X_train), Y_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(np.nan_to_num(X_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                  precision    recall  f1-score   support\n\n        mask_off       0.81      1.00      0.90       186\nnormal_breathing       0.93      0.97      0.95       184\n         talking       0.96      0.74      0.84       200\n           cough       0.00      0.00      0.00         6\n\n        accuracy                           0.89       576\n       macro avg       0.68      0.68      0.67       576\n    weighted avg       0.89      0.89      0.88       576\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred, target_names=['mask_off', 'normal_breathing', 'talking', 'cough']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "model_svm = svm.SVC()\n",
    "model_svm.fit(np.nan_to_num(X_train), Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                  precision    recall  f1-score   support\n\n        mask_off       0.78      1.00      0.87       186\nnormal_breathing       0.89      0.91      0.90       184\n         talking       0.96      0.71      0.82       200\n           cough       0.00      0.00      0.00         6\n\n        accuracy                           0.86       576\n       macro avg       0.66      0.65      0.65       576\n    weighted avg       0.87      0.86      0.85       576\n\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_svm.predict(np.nan_to_num(X_test))\n",
    "print(classification_report(Y_test, y_pred, target_names=['mask_off', 'normal_breathing', 'talking', 'cough'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name '_tree' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-b24d0f953a84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcoreml_model_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_svm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcoreml_model_knn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ResCls.mlmodel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/smart-ppe/lib/python3.8/site-packages/coremltools/converters/sklearn/_converter.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(sk_obj, input_features, output_feature_names)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;31m# several issues with the ordering of the classes are worked out.  For now,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;31m# to use custom class labels, directly import the internal function below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_converter_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_convert_sklearn_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     spec = _convert_sklearn_model(\n",
      "\u001b[0;32m~/miniconda3/envs/smart-ppe/lib/python3.8/site-packages/coremltools/converters/sklearn/_converter_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_LinearSVR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_linear_regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_decision_tree_classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_decision_tree_regressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_gradient_boosting_classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/smart-ppe/lib/python3.8/site-packages/coremltools/converters/sklearn/_decision_tree_classifier.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"classifier\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0msklearn_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_tree' is not defined"
     ]
    }
   ],
   "source": [
    "coreml_model_knn = ct.converters.sklearn.convert(model_svm)\n",
    "coreml_model_knn.save('ResCls.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}